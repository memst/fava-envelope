"""
This type stub file was generated by pyright.
"""

import unittest

"""
Tests for lexer.
"""
__copyright__ = ...
__license__ = ...
def print_tokens(tokens): # -> None:
    """A function for printing a list of tokens, for testing.

    Args:
      tokens: A list of token tuples.
    """
    ...

def lex_tokens(fun): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    """Decorator for test functions that will invoke a lexer on them.

    The lexer passes the list of tokens and errors to the test function.

    Args:
      fun: A test function to be decorated.
    Returns:
      The decorated function.
    """
    ...

class TestLexer(unittest.TestCase):
    """Test output of the lexer."""
    maxDiff = ...
    @lex_tokens
    def test_lex_iter(self, tokens, errors): # -> None:
        """\
          2013-05-18 2014-01-02 2014/01/02
          Assets:US:Bank:Checking
          Liabilities:US:Bank:Credit
          Other:Bank
          USD HOOL TEST_D TEST_3 TEST-D TEST-3 NT
          "Nice dinner at Mermaid Inn"
          ""
          123 123.45 123.456789 -123 -123.456789
          #sometag123
          ^sometag123
          somekey:
        """
        ...
    
    @lex_tokens
    def test_lex_unicode_account(self, tokens, errors): # -> None:
        """\
          Other:Bank Óthяr:Bあnk
          abc1:abc1 ΑβγⅠ:ΑβγⅠ ابجا:ابجا
        """
        ...
    
    @lex_tokens
    def test_lex_indent(self, tokens, errors): # -> None:
        """\
          2014-07-05 *
            Equity:Something
        """
        ...
    
    @lex_tokens
    def test_comma_currencies(self, tokens, errors): # -> None:
        """\
          USD,CAD,AUD
        """
        ...
    
    @lex_tokens
    def test_number_okay(self, tokens, errors): # -> None:
        """\
          1001 USD
          1002.00 USD
          -1001 USD
          -1002.00 USD
          +1001 USD
          +1002.00 USD
          1,001 USD
          1,002.00 USD
          -1,001 USD
          -1,002.00 USD
          +1,001 USD
          +1,002.00 USD
        """
        ...
    
    @lex_tokens
    def test_number_space(self, tokens, errors): # -> None:
        """\
          - 1002.00 USD
        """
        ...
    
    @lex_tokens
    def test_number_dots(self, tokens, errors): # -> None:
        """\
          1.234.00 USD
        """
        ...
    
    @lex_tokens
    def test_number_no_integer(self, tokens, errors): # -> None:
        """\
          .2347 USD
        """
        ...
    
    @lex_tokens
    def test_currency_number(self, tokens, errors): # -> None:
        """\
          555.00 CAD.11
        """
        ...
    
    @lex_tokens
    def test_currency_dash(self, tokens, errors): # -> None:
        """\
          TEST-DA
        """
        ...
    
    @lex_tokens
    def test_bad_date(self, tokens, errors): # -> None:
        """\
          2013-12-98
        """
        ...
    
    @lex_tokens
    def test_date_followed_by_number(self, tokens, errors): # -> None:
        """\
          2013-12-228
        """
        ...
    
    @lex_tokens
    def test_single_letter_account(self, tokens, errors): # -> None:
        """\
          Assets:A
        """
        ...
    
    @lex_tokens
    def test_account_names_with_numbers(self, tokens, errors): # -> None:
        """\
          Assets:Vouchers:99Ranch
          Assets:99Test
          Assets:signals
        """
        ...
    
    @lex_tokens
    def test_account_names_with_dash(self, tokens, errors): # -> None:
        """\
          Equity:Beginning-Balances
        """
        ...
    
    @lex_tokens
    def test_invalid_directive(self, tokens, errors): # -> None:
        """\
          2008-03-01 check Assets:BestBank:Savings 2340.19 USD
        """
        ...
    
    def test_string_too_long_warning(self): # -> None:
        ...
    
    def test_very_long_string(self): # -> None:
        ...
    
    @lex_tokens
    def test_no_final_newline(self, tokens, errors): # -> None:
        """\
          2014-01-01 open Assets:Temporary \
        """
        ...
    
    @lex_tokens
    def test_string_escaped(self, tokens, errors): # -> None:
        r'''
          "The Great \"Juju\""
          "The Great \t\n\r\f\b"
        '''
        ...
    
    @lex_tokens
    def test_string_newline(self, tokens, errors): # -> None:
        '"The Great\nJuju"'
        ...
    
    @lex_tokens
    def test_string_newline_long(self, tokens, errors): # -> None:
        '''
        "Forty
        world
        leaders
        and
        hundreds"
        '''
        ...
    
    def test_string_newline_toolong(self): # -> None:
        ...
    
    @lex_tokens
    def test_popmeta(self, tokens, errors): # -> None:
        '''
        popmeta location:
        '''
        ...
    
    @lex_tokens
    def test_null_true_false(self, tokens, errors): # -> None:
        '''
        TRUE FALSE NULL
        '''
        ...
    


class TestIgnoredLines(unittest.TestCase):
    @lex_tokens
    def test_ignored__long_comment(self, tokens, errors): # -> None:
        """
        ;; Long comment line about something something.
        """
        ...
    
    @lex_tokens
    def test_ignored__indented_comment(self, tokens, errors): # -> None:
        """
        option "title" "The Title"
          ;; Something something.
        """
        ...
    
    @lex_tokens
    def test_ignored__something_else(self, tokens, errors): # -> None:
        """
        Regular prose appearing mid-file which starts with a flag character.
        """
        ...
    
    @lex_tokens
    def test_ignored__something_else_non_flag(self, tokens, errors): # -> None:
        """
        Xxx this sentence starts with a non-flag character.
        """
        ...
    
    @lex_tokens
    def test_ignored__org_mode_title(self, tokens, errors): # -> None:
        """
        * This sentence is an org-mode title.
        """
        ...
    
    @lex_tokens
    def test_ignored__org_mode_drawer(self, tokens, errors): # -> None:
        """
        :PROPERTIES:
        :this: is an org-mode property drawer
        :END:
        """
        ...
    


class TestLexerErrors(unittest.TestCase):
    """Test lexer error handling.
    """
    @lex_tokens
    def test_lexer_invalid_token(self, tokens, errors): # -> None:
        """
          2000-01-01 open ` USD
        """
        ...
    
    @lex_tokens
    def test_lexer_exception__recovery(self, tokens, errors): # -> None:
        """
          2000-13-32 open Assets:Something

          2000-01-02 open Assets:Working
        """
        ...
    
    @lex_tokens
    def test_lexer_exception_DATE(self, tokens, errors): # -> None:
        """
          2000-13-32 open Assets:Something
        """
        ...
    
    def test_lexer_exception_substring_with_quotes(self): # -> None:
        ...
    


class TestLexerUnicode(unittest.TestCase):
    test_utf8_string = ...
    expected_utf8_string = ...
    test_latin1_string = ...
    expected_latin1_string = ...
    def test_bytes_encoded_utf8(self): # -> None:
        ...
    
    def test_bytes_encoded_latin1_invalid(self): # -> None:
        ...
    
    def test_bytes_encoded_latin1(self): # -> None:
        ...
    
    def test_bytes_encoded_utf16_invalid(self): # -> None:
        ...
    


class TestLexerMisc(unittest.TestCase):
    @lex_tokens
    def test_valid_commas_in_number(self, tokens, errors): # -> None:
        """\
          45,234.00
        """
        ...
    
    @lex_tokens
    def test_invalid_commas_in_integral(self, tokens, errors): # -> None:
        """\
          452,34.00
        """
        ...
    
    @lex_tokens
    def test_invalid_commas_in_fractional(self, tokens, errors): # -> None:
        """\
          45234.000,000
        """
        ...
    


if __name__ == '__main__':
    ...
